\section{Discussion}

% TODO: Edit
\subsection{Contributions}

This paper makes the following key contributions:

\begin{enumerate}
\item We introduce a pipeline for applying sparse dictionary learning methods specifically designed to discover interpretable neurobiological latents ("features").

\item Our pipeline is end-to-end from spatiotemporally binned neural data to interpretable latent discovery: containns functionality for neural data preprocessing, model training, model evaluation, and feature evaluation.

\item We provide systematic evaluation on multiple synthetic and natural large-scale neurobiological datasets, demonstrating the effectiveness of our approach across different species, brain regions, recording techniques, experimental conditions, and spatiotemporal scales.

\item We show that MSAE-derived features enable effective decoding of behavioral and stimulus variables, validating their biological relevance.

\item We release our code open-source with interactive tutorials for facilitating broader adoption in the neuroscience community.
\end{enumerate}

\subsection{Pros and Cons}

\textbf{Advantages}:
\begin{itemize}
    \item \textbf{Interpretability}: The sparse and multi-scale nature of the learned features facilitates direct interpretation and comparison with existing neuroscience knowledge.
    \item \textbf{Scalability}: The model architecture is designed to scale to large datasets with thousands of neurons and millions of time points.
    \item \textbf{Flexibility}: The framework can be adapted to various data modalities, including spike trains, calcium imaging, and LFP/EEG signals.
\end{itemize}

\textbf{Limitations}:
\begin{itemize}
    \item Model performance is sensitive to the choice of hyperparameters, requiring careful tuning and validation.
    \item  While our model reveals correlational structure, it does not inherently infer causal relationships between neural features and behavior.
    \item The model is a simplified representation of neural circuits and does not capture all aspects of biological complexity.
    \item Latent interpretability is subject to human subjectivity.
\end{itemize}

\subsection{Future Work}

\begin{itemize}
    
    \item Actually apply to other recording modalities
    \begin{itemize}
        \item LFP \& EEG (reconstruct voltage values from C channels over T time)
        \item Calcium imaging (reconstruct dF/F values from R RoIs over T time)
    \end{itemize}
    
    \item Actually apply to multimodal data
    \begin{itemize}
        \item e.g. reconstruct spikes from spikes + multimodal behavior (e.g. pose-tracking, gaze-tracking, etc.)
    \end{itemize}
    
    \item Use history to improve reconstructions and feature interpretability?
    \begin{itemize}
        \item While our codebase optionally allows for using history length, in practice we did not get improved reconstructions nor more interpretable latents, but in theory this approach could be improved to do so.
    \end{itemize}
    
    \item CLTs \& SCCs
    \begin{itemize}
        \item Cross-region prediction
        \item Brain diffing
    \end{itemize}

\end{itemize}
