\section{Results}

We evaluate our Multi-Scale Sparse Autoencoder approach on three major neural datasets, demonstrating the method's effectiveness across different brain regions, experimental paradigms, and recording techniques. Our results show that MSAEs can discover interpretable neural features while maintaining high reconstruction quality and enabling effective decoding of behavioral and stimulus variables.

\subsection{Allen Neuropixels Visual Coding Datasets}

\subsubsection{Dataset Description}

We analyze data from the Allen Institute's Neuropixels Visual Coding project, which provides high-density recordings from multiple brain regions in mice viewing natural images and movies. The dataset includes recordings from visual cortex (V1, LM, AL, PM, AM), hippocampus (CA1, CA3, DG), and thalamus (LGN, LP) across multiple experimental sessions.

% TODO: Add specific numbers once analysis is complete
\textbf{Data characteristics:}
\begin{itemize}
\item Number of sessions: X
\item Total recorded neurons: Y 
\item Recording duration: Z hours
\item Stimulus conditions: Natural images, natural movies, drifting gratings
\end{itemize}

\subsubsection{Discovered Features}

Our MSAE analysis reveals several classes of interpretable features in the visual system:

\textbf{Stimulus-specific features:} We identify features that respond selectively to specific visual stimuli, including:
\begin{itemize}
\item Edge detectors with various orientations and spatial frequencies
\item Motion-sensitive features tuned to specific directions and speeds
\item Object-selective features that activate for particular natural image categories
\item Temporal features that capture onset and offset responses to visual stimuli
\end{itemize}

\textbf{Cross-regional features:} Multi-scale analysis reveals features that coordinate activity across brain regions:
\begin{itemize}
\item Cortico-thalamic loops linking V1 and LGN activity
\item Hippocampal-cortical interactions during visual processing
\item Inter-cortical communication between visual areas
\end{itemize}

\textbf{Behavioral state features:} Features that correlate with the animal's behavioral state:
\begin{itemize}
\item Locomotion-related activity patterns
\item Arousal state indicators
\item Attention-related modulations during stimulus presentation
\end{itemize}

% TODO: Add figures showing example features
\begin{figure}[h]
\centering
% \includegraphics[width=0.8\textwidth]{figures/allen_features.pdf}
\caption{Representative features discovered in Allen Neuropixels data. (A) Stimulus-selective features showing orientation tuning. (B) Cross-regional features linking V1 and LGN. (C) Behavioral state features correlating with locomotion. (D) Temporal dynamics of discovered features across different scales.}
\label{fig:allen_features}
\end{figure}

\subsubsection{Comparison with Other Methods}

We compare MSAE features with those obtained from traditional dimensionality reduction methods:

\textbf{vs. Principal Component Analysis (PCA):}
\begin{itemize}
\item MSAE features show higher selectivity for specific stimuli
\item Better preservation of trial-to-trial variability structure
\item More interpretable spatial and temporal patterns
\end{itemize}

\textbf{vs. Independent Component Analysis (ICA):}
\begin{itemize}
\item MSAE provides better control over sparsity-interpretability trade-off
\item Superior reconstruction quality
\item More stable features across experimental sessions
\end{itemize}

\textbf{vs. Standard Sparse Autoencoders:}
\begin{itemize}
\item Multi-scale approach captures both fast and slow neural dynamics
\item Better generalization across different stimulus conditions
\item Improved decoding performance for behavioral variables
\end{itemize}

\subsubsection{Decoding Results}

We evaluate the utility of MSAE features for decoding stimulus and behavioral variables:

\textbf{Stimulus decoding:}
\begin{itemize}
\item Natural image classification: X\% accuracy (vs. Y\% for raw data)
\item Motion direction decoding: A\% accuracy (vs. B\% for PCA features)
\item Orientation discrimination: P\% accuracy (vs. Q\% for ICA features)
\end{itemize}

\textbf{Behavioral decoding:}
\begin{itemize}
\item Locomotion state: M\% accuracy
\item Pupil size (arousal): Correlation r = N
\item Reaction time prediction: Mean absolute error = O ms
\end{itemize}

% TODO: Add table with detailed decoding results
\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Decoding Task} & \textbf{MSAE} & \textbf{PCA} & \textbf{Raw Data} \\
\midrule
Natural Image Classification & X.X\% & Y.Y\% & Z.Z\% \\
Motion Direction & A.A\% & B.B\% & C.C\% \\
Locomotion State & M.M\% & N.N\% & O.O\% \\
\bottomrule
\end{tabular}
\caption{Decoding performance comparison across different feature extraction methods on Allen Neuropixels data.}
\label{tab:allen_decoding}
\end{table}

\subsection{Churchland Datasets}

\subsubsection{Dataset Description}

We analyze motor cortical recordings from the Churchland lab, focusing on reaching movements in non-human primates. These datasets provide insights into motor control and movement planning at the population level.

\textbf{Data characteristics:}
\begin{itemize}
\item Brain region: Motor cortex (M1) and premotor cortex (PMd)
\item Task: Delayed reaching movements to multiple targets
\item Number of sessions: X
\item Recorded neurons: Y per session
\item Trial types: Z different reach directions
\end{itemize}

\subsubsection{Motor Control Features}

MSAE analysis of motor cortical data reveals features relevant to movement control:

\textbf{Preparatory activity features:}
\begin{itemize}
\item Target-specific preparatory states during delay periods
\item Ramping activity patterns leading to movement onset
\item Population-level rotational dynamics during movement preparation
\end{itemize}

\textbf{Movement execution features:}
\begin{itemize}
\item Direction-tuned features active during reaching
\item Velocity-encoding features that track movement kinematics
\item Coordination features that organize population activity during movement
\end{itemize}

\textbf{Multi-scale temporal features:}
\begin{itemize}
\item Fast features (1-10ms) capturing spike timing precision
\item Intermediate features (10-100ms) reflecting neural oscillations
\item Slow features (100ms-1s) tracking movement trajectories
\end{itemize}

\subsubsection{Comparison with State-of-the-Art Methods}

We compare our approach with established methods for analyzing motor cortical data:

\textbf{vs. Factor Analysis (FA):}
\begin{itemize}
\item MSAE features show clearer separation between preparatory and movement periods
\item Better preservation of single-trial dynamics
\item More robust across different experimental sessions
\end{itemize}

\textbf{vs. Gaussian Process Factor Analysis (GPFA):}
\begin{itemize}
\item Comparable smoothness of extracted trajectories
\item Superior performance on discrete trial classification tasks
\item Better handling of different temporal scales simultaneously
\end{itemize}

\subsubsection{Motor Decoding Performance}

MSAE features enable accurate decoding of movement-related variables:

\textbf{Reach direction decoding:}
\begin{itemize}
\item Classification accuracy: X\% (8-way classification)
\item Improvement over baseline methods: +Y\%
\item Generalization across sessions: Z\% accuracy drop
\end{itemize}

\textbf{Movement velocity decoding:}
\begin{itemize}
\item Correlation with actual velocity: r = A
\item Mean squared error: B cm²/s²
\item Prediction horizon: Up to C ms before movement
\end{itemize}

\subsection{Aeon Dataset}

\subsubsection{Dataset Description}

We analyze data from the Aeon project, which provides continuous long-term recordings of freely behaving mice in enriched environments. This dataset allows us to study neural dynamics during naturalistic behaviors over extended time periods.

\textbf{Data characteristics:}
\begin{itemize}
\item Recording duration: Multiple weeks of continuous recording
\item Behavioral complexity: Natural foraging, social interactions, sleep-wake cycles
\item Brain regions: Multiple cortical and subcortical areas
\item Temporal scales: From milliseconds to circadian rhythms
\end{itemize}

\subsubsection{Long-term Neural Features}

The multi-scale nature of MSAE is particularly well-suited for analyzing long-term neural recordings:

\textbf{Circadian features:}
\begin{itemize}
\item Day-night activity cycles across brain regions
\item Sleep-wake state transitions
\item Ultradian rhythms in neural activity
\end{itemize}

\textbf{Behavioral episode features:}
\begin{itemize}
\item Foraging sequence patterns
\item Social interaction signatures
\item Exploration vs. exploitation modes
\end{itemize}

\textbf{Learning and adaptation features:}
\begin{itemize}
\item Features that change over days/weeks as animals adapt to environment
\item Plasticity-related patterns in neural connectivity
\item Memory consolidation signatures during sleep
\end{itemize}

\subsubsection{Naturalistic Behavior Decoding}

MSAE features enable decoding of complex naturalistic behaviors:

\textbf{Behavioral state classification:}
\begin{itemize}
\item Sleep vs. wake: X\% accuracy
\item Active vs. quiet wake: Y\% accuracy
\item REM vs. NREM sleep: Z\% accuracy
\end{itemize}

\textbf{Behavioral sequence prediction:}
\begin{itemize}
\item Next action prediction: A\% accuracy
\item Sequence completion: B\% accuracy over C-second horizons
\item Behavioral mode switching: D\% accuracy
\end{itemize}

% TODO: Add summary figure comparing all datasets
\begin{figure}[h]
\centering
% \includegraphics[width=\textwidth]{figures/summary_comparison.pdf}
\caption{Summary comparison of MSAE performance across all three datasets. (A) Reconstruction quality vs. sparsity trade-off. (B) Decoding performance for various tasks. (C) Feature interpretability scores. (D) Computational efficiency comparison.}
\label{fig:summary}
\end{figure}

\subsection{Hyperparameter Analysis}

We systematically analyze how key hyperparameters affect model performance and interpretability:

\subsubsection{Effect of Latent Dimension ($d_{\text{sae}}$)}

\begin{itemize}
\item \textbf{Low dimensions (d < 50):} High interpretability but poor reconstruction
\item \textbf{Medium dimensions (50 ≤ d ≤ 200):} Optimal balance for most applications
\item \textbf{High dimensions (d > 200):} Excellent reconstruction but reduced interpretability
\end{itemize}

\subsubsection{Impact of Top-k Sparsity}

\begin{itemize}
\item \textbf{Very sparse (k < 5):} Clear feature separation but information loss
\item \textbf{Moderate sparsity (5 ≤ k ≤ 20):} Good balance of interpretability and completeness
\item \textbf{Dense representations (k > 20):} High fidelity but reduced interpretability
\end{itemize}

The optimal hyperparameter settings depend on the specific application and the desired trade-off between interpretability and reconstruction quality. Our systematic sweeps provide guidelines for selecting appropriate values for different types of neural data and analysis goals.
