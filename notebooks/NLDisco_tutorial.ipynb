{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLDisco Tutorial\n",
    "\n",
    "This tutorial introduces **NLDisco** (**N**eural **L**atent **Disco**very pipeline).\n",
    "\n",
    "**Goal:** discover interpretable latents (i.e., *features*) in high-dimensional neural data.\n",
    "\n",
    "NLDisco trains sparse autoencoders (SAEs): shallow encoder–decoder models trained to reconstruct neural activity ($y$ in the figure) from a set of sparsely active dictionary elements (hidden units, $d$). Sparsity encourages a monosemantic dictionary, where each unit corresponds to a single interpretable feature, making SAEs a simple but effective tool for neural latent discovery. This approach has had many successes in the field of AI mechanistic interpretability.\n",
    "\n",
    "![](./tutorial_figures/sae.svg)\n",
    "\n",
    "We consider a latent’s interpretability in two key aspects: \n",
    "1. its correspondence to a specific external variable – a \"natural\" behavioral or environmental feature\n",
    "2. its explicit composition from contributing neural activity\n",
    "\n",
    "**Terminology:**\n",
    "\n",
    "In this tutorial we will be refferring to the following terms:\n",
    "- *Features:* interpretable latents (latent dimensions that align with a meaningful behavioural or environmental variable)\n",
    "- *Neurons:* biological neurons\n",
    "- *Units:* hidden units of the SAE (model neurons, each corresponding to one latent dimension)\n",
    "\n",
    "**NLDisco pipeline:**\n",
    "\n",
    "1. Load and prepare data\n",
    "    - Spike data (in the form of binned spike counts as $[examples \\times neurons]$)\n",
    "    - Behavioral and/or environmental (meta)data\n",
    "\n",
    "2. Train SAEs \n",
    "    - Train them to reconstruct the neural data (in this case, from the MC Maze dataset)\n",
    "    - Validate the quality of the SAEs by looking at the sparsity of the latent activations and reconstruction quality of the neural data\n",
    "\n",
    "3. Save or load the SAE activations\n",
    "\n",
    "4. Find features\n",
    "    - Automatically generate promising mappings between SAE units (latents) and metadata\n",
    "    - Find meaningful features and their associated biological neurons using an interactive dashboard\n",
    "        - The mapping is a starting point to guide the search\n",
    "        - Or the user can also choose to look through units manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Environment setup:**\n",
    "\n",
    "Prerequisite: an installed version of [pixi](https://pixi.sh/latest/)\n",
    "\n",
    "Steps:\n",
    "1. In the repo's root directory, run `pixi install --manifest-path ./pyproject.toml`. This will create an environment in a newly created `.pixi/envs` folder.\n",
    "2. Run `pixi run postinstall`\n",
    "\n",
    "**Data download:**\n",
    "\n",
    "Once your environment is set up, use it as a kernel for this notebook and run the cell below to automatically download and preprocess the [churchland_shenoy_neural_2012 dataset](https://brainsets.readthedocs.io/en/latest/glossary/brainsets.html#churchland-shenoy-neural-2012) (also known as MC_Maze). With the data ready, you can jump straight into the tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nldisco import mc_maze\n",
    "\n",
    "# Directories for raw and processed data\n",
    "raw_data_dir = \"../data/raw\"\n",
    "processed_data_dir = \"../data/processed\"\n",
    "\n",
    "# Subject name and number of their sessions to download\n",
    "# Max 4 for jenkins and 3 for nitschke\n",
    "# Be aware that these files are large (~2-7GB each)\n",
    "subject_name = \"nitschke\"  # \"jenkins\" or \"nitschke\"\n",
    "num_files = 1  \n",
    "\n",
    "mc_maze.download_and_preprocess(raw_data_dir, processed_data_dir, subject_name, num_files=num_files)\n",
    "\n",
    "# To load all the data, use:\n",
    "# mc_maze.download_and_preprocess(raw_data_dir, processed_data_dir, \"jenkins\", num_files=4)\n",
    "# mc_maze.download_and_preprocess(raw_data_dir, processed_data_dir, \"nitschke\", num_files=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set notebook settings.\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import packages.\"\"\"\n",
    "\n",
    "# Standard library\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# IPython/Jupyter\n",
    "from IPython.display import display\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch as t\n",
    "from einops import asnumpy, reduce\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Local project modules\n",
    "from nldisco import train as mt\n",
    "from nldisco import mc_maze\n",
    "from nldisco.train_val_split import train_val_split_by_proportion, train_val_split_by_session\n",
    "from nldisco import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and prepare data\n",
    "\n",
    "In the churchland_shenoy_neural_2012 dataset, the subjects are performing a center-out reaching task on a variety of different maze configurations. Each maze configuration comes in 3 versions:\n",
    "- 1 target and no barriers.\n",
    "- 1 target with barriers.\n",
    "- 3 targets, with barriers. But 2 of the targets are distractors and unaccessible given the barrier configuration.\n",
    "\n",
    "So maze conditions 1, 2, 3 are related; as are maze conditions 4, 5, 6; and so on.\n",
    "Neural activity was recorded from the dorsal premotor (PMd) and primary motor (M1) cortices. A variety of other data (monkey hand position, velocity and acceleration, gaze position...) is also provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare spike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(r\"../data/processed\")\n",
    "save_path = Path(r\"../saved_sae_unit_activations\")\n",
    "subject_name = \"nitschke\"  # \"jenkins\" or \"nitschke\"\n",
    "\n",
    "# Load\n",
    "sessions = mc_maze.load_sessions(data_path, subject_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bin spike data.\"\"\"\n",
    "\n",
    "bin_size = 0.05 # in seconds\n",
    "spikes_df = mc_maze.bin_spike_data(sessions, bin_size) # this can take several minutes\n",
    "\n",
    "display(spikes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Quick plots and stats to get a sense of the spike data.\"\"\"\n",
    "\n",
    "print(\"Firing rates distribution:\")\n",
    "# Compute mean firing rate (Hz) per neuron\n",
    "duration_sec = len(spikes_df) * bin_size\n",
    "mean_firing_rates = spikes_df.sum(axis=0) / duration_sec  # spikes_arr/sec\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(mean_firing_rates, bins=30, edgecolor='black')\n",
    "plt.xlabel('Mean Firing Rate (Hz)')\n",
    "plt.ylabel('Number of Neurons')\n",
    "plt.title('Distribution of Mean Firing Rates per Neuron')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Print stats\n",
    "print(\"Mean: {:.2f} Hz\".format(mean_firing_rates.mean()))\n",
    "print(\"Range: {:.2f}–{:.2f} Hz\".format(mean_firing_rates.min(), mean_firing_rates.max()))\n",
    "\n",
    "print(\"\\n\\nSpike count distribution and sparsity stats:\")\n",
    "# Flatten spike counts\n",
    "flattened_spike_counts = spikes_df.values.flatten()\n",
    "# Define bins that align exactly to integer spike counts\n",
    "max_count = flattened_spike_counts.max()\n",
    "bins = np.arange(0, max_count + 2) - 0.5  # centers bins on integers\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(flattened_spike_counts, bins=bins, edgecolor='black')\n",
    "plt.title(\"Distribution of Spike Counts per Neuron per Time Bin\")\n",
    "plt.xlabel(\"Spike Count\")\n",
    "plt.ylabel(\"Number of Neuron-Bin Combinations\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Print stats\n",
    "frac_nonzero_bins = (spikes_df != 0).values.sum() / spikes_df.size\n",
    "frac_nonzero_examples = (spikes_df.sum(axis=1) > 0).mean()\n",
    "print(f\"Fraction of non-zero bins: {frac_nonzero_bins:.4f}\")\n",
    "print(f\"Fraction of non-zero examples: {frac_nonzero_examples:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare environment / behavior (meta)data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and collate metadata (hand/eye/events) across sessions\n",
    "metadata, trials_df = mc_maze.retrieve_metadata(sessions) # this can take a minute\n",
    "# Bin metadata to the match the binned spikes_df\n",
    "metadata_binned = mc_maze.bin_metadata(metadata, trials_df, bin_size, spikes_df.index)\n",
    "\n",
    "print(\"Metadata:\")\n",
    "display(metadata)\n",
    "print(\"Binned metadata:\")\n",
    "display(metadata_binned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train/val split, smooth and normalize spikes.\"\"\"\n",
    "\n",
    "split_by_session = False # if False, will split by proportion\n",
    "\n",
    "if split_by_session:\n",
    "    train_trials, val_trials = train_val_split_by_session(\n",
    "        metadata_binned[\"trial_idx\"].to_numpy(),\n",
    "        metadata_binned[\"session\"].to_numpy(),\n",
    "        train_sessions=[1, 2],  # pick your training sessions\n",
    "        shuffle=True,\n",
    "        seed=0,\n",
    "    )\n",
    "else:\n",
    "    train_trials, val_trials = train_val_split_by_proportion(\n",
    "        metadata_binned[\"trial_idx\"].values,\n",
    "        train_proportion=0.8,\n",
    "        shuffle=True,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "# Create boolean masks to split metadata and spikes into train/val sets\n",
    "train_mask = metadata_binned['trial_idx'].isin(train_trials)\n",
    "val_mask = metadata_binned['trial_idx'].isin(val_trials)\n",
    "\n",
    "# Split metadata\n",
    "metadata_binned_train = metadata_binned[train_mask].reset_index(drop=True)\n",
    "metadata_binned_val = metadata_binned[val_mask].reset_index(drop=True)\n",
    "\n",
    "# Split spikes \n",
    "spikes_arr = spikes_df.values.astype(np.float32)\n",
    "spikes_train_arr = spikes_arr[train_mask]\n",
    "spikes_val_arr = spikes_arr[val_mask]\n",
    "\n",
    "# Smooth spikes\n",
    "sigma = 0.05 / bin_size\n",
    "spikes_train_arr = gaussian_filter1d(spikes_train_arr, sigma=sigma, axis=0)\n",
    "spikes_val_arr = gaussian_filter1d(spikes_val_arr, sigma=sigma, axis=0)\n",
    "\n",
    "# Normalize spikes (fit normalization on training data only)\n",
    "train_max = spikes_train_arr.max()\n",
    "spikes_train_arr = spikes_train_arr / train_max\n",
    "spikes_val_arr = spikes_val_arr / train_max\n",
    "\n",
    "# Summary\n",
    "print(f\"Train set: {len(train_trials)} trials ({train_mask.sum()} time bins)\")\n",
    "print(f\"Val set: {len(val_trials)} trials ({val_mask.sum()} time bins)\")\n",
    "print(f\"Spike data shapes: train {spikes_train_arr.shape}, val {spikes_val_arr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert to torch tensors and move to device.\"\"\"\n",
    "\n",
    "# it's best to have a gpu for training!\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")\n",
    "\n",
    "spikes_train = t.from_numpy(spikes_train_arr).to(device).to(dtype=t.bfloat16)\n",
    "spikes_val = t.from_numpy(spikes_val_arr).to(device).to(dtype=t.bfloat16)\n",
    "\n",
    "display(spikes_train)\n",
    "display(spikes_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train SAEs\n",
    "\n",
    "> If desired, you can choose to skip this section and load pre-saved SAE unit activations instead. A set of activations per subject (Jenkins and Nitschke) is provided - go to section \"3. Save/load SAE activations\" for more information. It is however still highly recommended to read the rest of this section to understand how the SAEs are trained.\n",
    "\n",
    "This code trains 2 SAEs with identical setups so that you can compare the different instances and ensure they both give similar results. For each time bin of neural data in the train and val sets, the SAEs' hidden-layer unit activations are calculated, and it is these activations that will be used to find a unit's correspondance with external variables (features). A particularity of the NLDisco pipeline below is that it trains *Matryoshka* SAEs.\n",
    "\n",
    "**Matryoshka architecture:**\n",
    "\n",
    "The Matryoshka architecture segments the latent space into multiple levels, each of which attempts a full reconstruction of the target neural activity. Black boxes indicate the latents involved in a given level, while light-red boxes indicate additional latents recruited at lower levels. A top-$k$ selection is used to choose which latents to recruit for reconstruction at each level (yellow neuron within each light-red box, $k=1$ for this example figure). \n",
    "\n",
    "This hierarchical arrangement is motivated by the idea that multi-scale feature learning could mitigate “feature absorption” (where broad features dominate more specific ones), potentially allowing both coarse and detailed patterns to be represented simultaneously.\n",
    "\n",
    "- Latents in the highest level ($L_1$) typically correspond to broad, high-level features (e.g., a round object), \n",
    "- Latents exclusive to the lowest level ($L_3$) often correspond to more specific, fine-grained features (e.g., a basketball)\n",
    "\n",
    "![](./tutorial_figures/msae.svg)\n",
    "\n",
    "**Key training parameters to play with:**\n",
    "\n",
    "`SaeConfig` (model-level):\n",
    "- `dsae_topk_map`: how many top-k units are kept active at each level (controls sparsity per level)\n",
    "- `dsae_loss_x_map`: relative weight of each Matryoshka level to the overall reconstruction loss\n",
    "\n",
    "`optimize()` (optimizer-level):\n",
    "- `n_steps`: total training steps\n",
    "- `batch_sz`: how many examples per batch\n",
    "- `lr` (set in optimizer): learning rate used by whatever optimizer you choose (e.g. Adam below) and you can optionally use a scheduler (`use_lr_sched=True`)\n",
    "- `dead_neuron_window`: number of steps a unit can stay inactive before being flagged as “dead”  \n",
    "  - Dead units are revived with an auxiliary loss: instead of reconstructing the full input, they try to reconstruct only the residual error (the part the active units failed to capture)\n",
    "  - This gives inactive units a chance to become useful again, preventing them from staying permanently silent   \n",
    "- `loss_fn` – reconstruction objective: built-ins are mse and msle, or you can pass a custom callable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set config.\"\"\"\n",
    "\n",
    "dsae_topk_map = {256: 8, 512: 16, 1024: 24} # total of 1024 units, 3 overlapping levels: 0-256, 0-512 and 0-1024\n",
    "dsae_topk_map = dict(sorted(dsae_topk_map.items()))  # ensure sorted from smallest to largest\n",
    "dsae_loss_x_map = {256: 1, 512: 1.25, 1024: 1.5}\n",
    "dsae_loss_x_map = dict(sorted(dsae_loss_x_map.items()))\n",
    "dsae = max(dsae_topk_map.keys())\n",
    "n_inst = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train model.\"\"\"\n",
    "\n",
    "sae_cfg = mt.SaeConfig(\n",
    "    n_input_ae=spikes_train.shape[1],\n",
    "    dsae_topk_map=dsae_topk_map,\n",
    "    dsae_loss_x_map=dsae_loss_x_map,\n",
    "    n_instances=n_inst,\n",
    ")\n",
    "sae = mt.Sae(sae_cfg).to(device)\n",
    "loss_fn = mt.msle\n",
    "tau = 1.0\n",
    "lr = 5e-3\n",
    "\n",
    "n_epochs = 20\n",
    "batch_sz = 1024\n",
    "n_steps = (spikes_train.shape[0] // batch_sz) * n_epochs\n",
    "log_freq = max(1, n_steps // n_epochs // 2)\n",
    "dead_unit_window = max(1, n_steps // n_epochs // 3)\n",
    "\n",
    "data_log = mt.optimize(  # train model\n",
    "    spk_cts=spikes_train,\n",
    "    sae=sae,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=t.optim.Adam(sae.parameters(), lr=lr),\n",
    "    use_lr_sched=True,\n",
    "    dead_neuron_window=dead_unit_window,\n",
    "    n_steps=n_steps,\n",
    "    log_freq=log_freq,\n",
    "    batch_sz=batch_sz,\n",
    "    log_wandb=False,\n",
    "    plot_l0=False,\n",
    "    tau=tau,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check for nans in weights.\"\"\"\n",
    "\n",
    "sae.W_dec.isnan().sum(), sae.W_enc.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize weights.\"\"\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for inst in range(n_inst):\n",
    "    W_dec_flat = asnumpy(sae.W_dec[inst].float()).ravel()\n",
    "    sns.histplot(W_dec_flat, bins=1000, stat=\"probability\", alpha=0.7, label=f\"SAE {inst}\")\n",
    "    \n",
    "ax.set_title(\"SAE decoder weights\")\n",
    "ax.set_xlabel(\"Weight value\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize metrics over all examples and neurons.\"\"\"\n",
    "\n",
    "topk_acts_4d_train, recon_spk_cts_train, r2_per_neuron_train, _, cossim_per_neuron_train, _ = mt.eval_model(\n",
    "    spikes_train, sae, batch_sz=batch_sz\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculate variance explained of summed spike counts.\"\"\"\n",
    "\n",
    "n_recon_examples = recon_spk_cts_train.shape[0]\n",
    "recon_summed_spk_cts = reduce(recon_spk_cts_train, \"example inst neuron -> example inst\", \"sum\")\n",
    "\n",
    "actual_summed_spk_cts = reduce(spikes_train, \"example neuron -> example\", \"sum\")\n",
    "actual_summed_spk_cts = actual_summed_spk_cts[:n_recon_examples]  # trim to match\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    r2 = r2_score(\n",
    "        asnumpy(actual_summed_spk_cts.float()),\n",
    "        asnumpy(recon_summed_spk_cts[:, inst].float()),\n",
    "    )\n",
    "    print(f\"SAE instance {inst} R² (summed spike count over all neurons per example) = {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bad neurons and retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Remove bad neurons and retrain.\"\"\"\n",
    "\n",
    "# Set threshold for removing neurons\n",
    "r2_thresh = 0.1\n",
    "inst = 0\n",
    "r2_inst = r2_per_neuron_train[:, inst]\n",
    "keep_mask = r2_inst > r2_thresh\n",
    "print(f\"frac neurons above {r2_thresh=}: {keep_mask.sum() / keep_mask.shape[0]:.2f}\")\n",
    "print(f\"Number to keep: {keep_mask.sum()} / {keep_mask.shape[0]}\")\n",
    "\n",
    "if keep_mask.all():\n",
    "    print(\"All neurons pass threshold — skipping retrain.\")\n",
    "    spikes_train_pruned = spikes_train\n",
    "    spikes_val_pruned = spikes_val\n",
    "else:\n",
    "    # Prune\n",
    "    spikes_train_pruned = spikes_train[:, keep_mask]\n",
    "    spikes_val_pruned = spikes_val[:, keep_mask]\n",
    "\n",
    "    # Retrain SAE on pruned train data\n",
    "    sae_cfg = mt.SaeConfig(\n",
    "        n_input_ae=spikes_train_pruned.shape[1],\n",
    "        dsae_topk_map=dsae_topk_map,\n",
    "        dsae_loss_x_map=dsae_loss_x_map,\n",
    "        seq_len=1,\n",
    "        n_instances=n_inst,\n",
    "    )\n",
    "    sae = mt.Sae(sae_cfg).to(device)\n",
    "    loss_fn = mt.msle\n",
    "    tau = 1.0\n",
    "    lr = 5e-3\n",
    "\n",
    "    n_epochs = 20\n",
    "    batch_sz = 1024\n",
    "    n_steps = (spikes_train_pruned.shape[0] // batch_sz) * n_epochs\n",
    "    log_freq = max(1, n_steps // n_epochs // 2)\n",
    "    dead_unit_window = max(1, n_steps // n_epochs // 3)\n",
    "\n",
    "    data_log = mt.optimize(\n",
    "        spk_cts=spikes_train_pruned,\n",
    "        sae=sae,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=t.optim.Adam(sae.parameters(), lr=lr),\n",
    "        use_lr_sched=True,\n",
    "        dead_neuron_window=dead_unit_window,\n",
    "        n_steps=n_steps,\n",
    "        log_freq=log_freq,\n",
    "        batch_sz=batch_sz,\n",
    "        log_wandb=False,\n",
    "        plot_l0=False,\n",
    "        tau=tau,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Re-visualize metrics over all examples and neurons.\"\"\"\n",
    "\n",
    "if keep_mask.all():\n",
    "    print(\"All neurons pass threshold — skipping re-visualization.\")\n",
    "else:\n",
    "    topk_acts_4d_train, recon_spk_cts_train, r2_per_neuron_train, _, cossim_per_neuron_train, _ = mt.eval_model(\n",
    "        spikes_train_pruned, sae, batch_sz=batch_sz\n",
    "    )\n",
    "\n",
    "    n_recon_examples_train = recon_spk_cts_train.shape[0]\n",
    "    recon_summed_train = reduce(recon_spk_cts_train, \"example inst neuron -> example inst\", \"sum\")\n",
    "\n",
    "    actual_summed_train = reduce(spikes_train_pruned, \"example neuron -> example\", \"sum\")\n",
    "    actual_summed_train = actual_summed_train[:n_recon_examples_train]\n",
    "\n",
    "    for inst in range(n_inst):\n",
    "        r2 = r2_score(\n",
    "            asnumpy(actual_summed_train.float()),\n",
    "            asnumpy(recon_summed_train[:, inst].float()),\n",
    "        )\n",
    "        print(f\"SAE instance {inst} R² (summed spike count per example) = {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize metrics on validation data.\"\"\"\n",
    "\n",
    "if spikes_val_pruned.shape[0] == 0:\n",
    "    print(\"No validation data available.\")\n",
    "else:\n",
    "    print(\"Validation data metrics:\")\n",
    "\n",
    "    topk_acts_4d_val, recon_spk_cts_va, r2_per_neuron_va, _, cossim_per_neuron_va, _ = mt.eval_model(\n",
    "        spikes_val_pruned, sae, batch_sz=batch_sz\n",
    "    )\n",
    "\n",
    "    n_recon_examples_val = recon_spk_cts_va.shape[0]\n",
    "    recon_summed_val = reduce(recon_spk_cts_va, \"example inst neuron -> example inst\", \"sum\")\n",
    "\n",
    "    actual_summed_val = reduce(spikes_val_pruned, \"example neuron -> example\", \"sum\")\n",
    "    actual_summed_val = actual_summed_val[:n_recon_examples_val]\n",
    "\n",
    "    for inst in range(n_inst):\n",
    "        r2 = r2_score(\n",
    "            asnumpy(actual_summed_val.float()),\n",
    "            asnumpy(recon_summed_val[:, inst].float()),\n",
    "        )\n",
    "        print(f\"SAE instance {inst} R² (summed spike count per example) = {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save/load SAE activations\n",
    "\n",
    "A set of activations per subject (Jenkins and Nitschke) is provided in the `saved_sae_unit_activations` folder. They were both generated using a split by proportion (80/20 train/val split). If you want to use them, switch the load_activations option below to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load saved activations if available; otherwise build acts_df and (optionally) save.\"\"\"\n",
    "\n",
    "load_activations = False\n",
    "save_activations = True\n",
    "activations_file_train = \"sae_activations_train.parquet\"\n",
    "activations_file_val = \"sae_activations_val.parquet\"\n",
    "mask_file_train = \"train_mask.parquet\"\n",
    "mask_file_val = \"val_mask.parquet\"\n",
    "\n",
    "# Build save path (same style as before)\n",
    "session_dates = []\n",
    "for session in sessions:\n",
    "    session_date = datetime.fromtimestamp(session.session.recording_date).strftime(\"%Y%m%d\")\n",
    "    session_dates.append(session_date)\n",
    "session_dates_str = \"_\".join(session_dates)\n",
    "\n",
    "activations_save_path = save_path / f\"{subject_name}_{session_dates_str}\" / \"sae_activations\"\n",
    "activations_save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if load_activations:\n",
    "    acts_df_train = pd.read_parquet(activations_save_path / activations_file_train)\n",
    "    acts_df_val = pd.read_parquet(activations_save_path / activations_file_val) if (activations_save_path / activations_file_val).exists() else None\n",
    "    train_mask = pd.read_parquet(activations_save_path / mask_file_train)[\"mask\"]\n",
    "    val_mask = pd.read_parquet(activations_save_path / mask_file_val)[\"mask\"]\n",
    "    print(f\"Loaded activations from {activations_save_path}\")\n",
    "else:\n",
    "    # Train\n",
    "    arr_tr = asnumpy(topk_acts_4d_train)  # [example_idx, instance_idx, unit_idx, activation_value]\n",
    "    # Sparse activations (tight dtypes on indices, fp32 values)\n",
    "    acts_df_train = pd.DataFrame({\n",
    "        \"example_idx\": arr_tr[:, 0].astype(int),\n",
    "        \"instance_idx\": arr_tr[:, 1].astype(int),\n",
    "        \"unit_idx\": arr_tr[:, 2].astype(int),\n",
    "        \"activation_value\": arr_tr[:, 3].astype(np.float32),\n",
    "    })\n",
    "\n",
    "    if spikes_val_pruned.shape[0] > 0:\n",
    "        # Val\n",
    "        arr_va = asnumpy(topk_acts_4d_val)\n",
    "        acts_df_val = pd.DataFrame({\n",
    "            \"example_idx\": arr_va[:, 0].astype(int),\n",
    "            \"instance_idx\": arr_va[:, 1].astype(int),\n",
    "            \"unit_idx\": arr_va[:, 2].astype(int),\n",
    "            \"activation_value\": arr_va[:, 3].astype(np.float32),\n",
    "        })\n",
    "    else:\n",
    "        acts_df_val = None\n",
    "\n",
    "    n_examples_train = (int(acts_df_train[\"example_idx\"].max()) + 1)\n",
    "    std_threshold = 1e-6\n",
    "\n",
    "    # Precompute squared values once, then sum both in one grouped pass\n",
    "    acts_df_train_with_sq = acts_df_train.assign(activation_value_sq=acts_df_train[\"activation_value\"] ** 2)\n",
    "\n",
    "    unit_stats = (\n",
    "        acts_df_train_with_sq.groupby([\"instance_idx\", \"unit_idx\"], as_index=False)\n",
    "          .agg(sum_val=(\"activation_value\", \"sum\"),\n",
    "               sum_sq=(\"activation_value_sq\", \"sum\"))\n",
    "    )\n",
    "    # Population variance which takes into account missing rows where activations are zero\n",
    "    unit_stats[\"mean\"] = unit_stats[\"sum_val\"] / n_examples_train\n",
    "    unit_stats[\"var\"]  = (unit_stats[\"sum_sq\"] / n_examples_train) - unit_stats[\"mean\"]**2\n",
    "    unit_stats[\"std\"]  = np.sqrt(np.clip(unit_stats[\"var\"].to_numpy(), 0.0, None))\n",
    "\n",
    "    kept_unit = unit_stats.loc[unit_stats[\"std\"] > std_threshold, [\"instance_idx\", \"unit_idx\"]]\n",
    "    n_dropped = len(unit_stats) - len(kept_unit)\n",
    "\n",
    "    if n_dropped:\n",
    "        # Semi-join to keep only surviving (instance, unit) pairs\n",
    "        acts_df_train = acts_df_train.merge(kept_unit, on=[\"instance_idx\", \"unit_idx\"], how=\"inner\")\n",
    "        acts_df_val = acts_df_val.merge(kept_unit, on=[\"instance_idx\", \"unit_idx\"], how=\"inner\") if (spikes_val_pruned.shape[0] > 0) else None\n",
    "        print(f\"Pruned {n_dropped} units (std ≤ {std_threshold}). Kept {len(kept_unit)}.\")\n",
    "\n",
    "    if save_activations:\n",
    "        acts_df_train.to_parquet(activations_save_path / activations_file_train, index=False)\n",
    "        acts_df_val.to_parquet(activations_save_path / activations_file_val, index=False) if spikes_val_pruned.shape[0] > 0 else None\n",
    "        train_mask.to_frame(name=\"mask\").to_parquet(activations_save_path / mask_file_train, index=True)\n",
    "        val_mask.to_frame(name=\"mask\").to_parquet(activations_save_path / mask_file_val, index=True)\n",
    "        print(f\"Saved activations to {activations_save_path}\")\n",
    "\n",
    "if acts_df_val is not None:\n",
    "    print(f\"Activations: \\nTrain shape: {acts_df_train.shape}, Val shape: {acts_df_val.shape}\")\n",
    "else:\n",
    "    print(f\"Activations: \\nTrain shape: {acts_df_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Find features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pick whether to find features in training or validation set.\"\"\"\n",
    "\n",
    "search_train = True\n",
    "\n",
    "if search_train:\n",
    "    acts_df_split = acts_df_train\n",
    "    metadata_binned_split = metadata_binned[train_mask].copy()\n",
    "    spikes_df_split = spikes_df[train_mask].copy()\n",
    "else:\n",
    "    acts_df_split = acts_df_val\n",
    "    metadata_binned_split = metadata_binned[val_mask].copy()\n",
    "    spikes_df_split = spikes_df[val_mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically map units to metadata\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "Units are mapped to metadata variables through the calculation of a selectivity score. For a unit $u$ and condition $c$ (variable/value combination e.g., velocity is between 0 and 1, or maze condition = 3, etc.):\n",
    "\n",
    "$$\n",
    "\\text{activation\\_frac\\_during} =\n",
    "\\frac{\\#\\{\\text{activations of } u \\text{ in examples with } c\\}}\n",
    "     {\\#\\{\\text{examples with } c\\}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{activation\\_frac\\_outside} =\n",
    "\\frac{\\#\\{\\text{activations of } u \\text{ in examples without } c\\}}\n",
    "     {\\#\\{\\text{examples without } c\\}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{selectivity\\_score} =\n",
    "\\frac{\\text{activation\\_frac\\_during}}\n",
    "     {\\text{activation\\_frac\\_during} + \\text{activation\\_frac\\_outside}}\n",
    "$$\n",
    "\n",
    "- $\\approx 1$: unit mainly active *during* the condition (highly selective)  \n",
    "- $\\approx 0.5$: unit active equally in/out (not selective)  \n",
    "- $\\approx 0$: unit mostly active *outside* the condition\n",
    "\n",
    "The map_units_to_metadata function:\n",
    "1. For discrete variables: computes activation fractions + selectivity score per condition value.  \n",
    "2. For continuous variables: bins, then reuses discrete analysis.  \n",
    "3. Results are ranked by selectivity score and the `top_n_mappings` are returned.\n",
    "\n",
    "**Key arguments to play with:**\n",
    "- `discrete_vars` and `continuous_vars`: as default only one of each was included because the function takes time to run, but you may be interested in exploring different or additional variables\n",
    "- `n_bins_continuous`: number of bins for continuous variables. This will affect whether you find more general features (small number of bins so you have less granularity e.g., you can only distinguish between fast vs slow hand velocity) or specific features (larger number of bins for more granularity e.g., you can now distinguish between very fast vs fast vs intermediate vs slow vs very slow hand velocity)\n",
    "- `min_activation_frac`: minimum fraction of condition examples a unit must activate in\n",
    "- `top_n_mappings`: number of highest-scoring mappings kept per variable/value/instance combination (default `3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Map units to metadata variables.\"\"\"\n",
    "\n",
    "# discrete_vars = ['event', 'maze_condition', 'barriers', 'targets', 'hit_position_x', 'hit_position_y', 'hit_position_angle']\n",
    "# continuous_vars = ['vel_magnitude', 'accel_magnitude', 'movement_angle']\n",
    "discrete_vars = ['event']\n",
    "continuous_vars = ['vel_magnitude']\n",
    "unit_metadata_mapping = pipeline.map_units_to_metadata( # this can take a minute\n",
    "    acts_df_split, metadata_binned_split,\n",
    "    discrete_vars=discrete_vars,\n",
    "    continuous_vars=continuous_vars,\n",
    "    min_activation_frac=0.5,\n",
    "    n_bins_continuous=[12],\n",
    "    top_n_mappings=5\n",
    ")\n",
    "unit_metadata_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find meaningful features and their associated neurons\n",
    "\n",
    "The code below generates a dashboard like this one, providing an interactive way to explore the SAE units in the search for meaningful features and their associated neurons:\n",
    "\n",
    "![](./tutorial_figures/feature_finding_dashboard.png)\n",
    "\n",
    "The unit_metadata_mapping dataframe generated just previously is used as a starting point to identify promising features (\"preset\" option on the dashboard). If you want more preset options to explore, feel free to return to the \"Automatically map units to metadata\" section and play with the arguments that control the mapping process.\n",
    "\n",
    "You may also choose to look through units manually, though this tends to take more time (\"manual selection\" option on the dashboard).\n",
    "\n",
    "Remember:\n",
    "- Matryoshka SAEs split units across multiple levels, with higher levels capturing broad patterns and lower levels capturing more specific ones. Check the `dsae` settings you used to train your SAEs to see what units were allocated to each level.\n",
    "- The neural recordings come from two brain regions (PMd and M1). Use the `neurons_df` dataframe generated below to look up the mapping of neuron IDs to brain regions - this can help you see whether particular features are driven more strongly by neurons in one region or the other.\n",
    "- By default, this tutorial set `search_train = True` at the beginning of this section, so the feature search runs on the training set. You can switch to the validation set instead, which lets you check that the SAEs generalise to unseen data (and to unseen sessions if you chose to split by session in section \"1. Load and prepare data\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print neuron to brain region mapping for reference.\"\"\"\n",
    "\n",
    "neuron_ids = [u.decode() for u in session.units.id]\n",
    "neurons_df = pd.DataFrame({\n",
    "    \"neuron_id\": [int(u.split(\"elec\")[1]) for u in neuron_ids],\n",
    "    \"region\": [\"PMd\" if \"group_1\" in u else \"M1\" for u in neuron_ids]\n",
    "})\n",
    "\n",
    "neurons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Feature finding dashboard.\"\"\"\n",
    "\n",
    "pipeline.build_feature_finding_dashboard(\n",
    "    unit_metadata_mapping=unit_metadata_mapping,\n",
    "    acts_df=acts_df_split,\n",
    "    spikes_df=spikes_df_split,\n",
    "    metadata_binned=metadata_binned_split\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
